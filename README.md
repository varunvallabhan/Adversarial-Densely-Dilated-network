# Adversarial-Densely-Dilated-network
ADDN or Adversarial Densely Dilated network is a GAN based segmentation approach which uses DDN(sense Dilated Network) as segmentor.




Guide to install jupyter notebook.
	https://jupyter.org/install

Guide to open a jupyter notebook.
	https://jupyter.readthedocs.io/en/latest/running.html
-----------------------------------------------------------------------------------------------------------------------------------------

REQUIRED PACKAGES:

openCV- pip install opencv-contrib-python
Tensorflow- pip install tensorflow
keras- pip install keras
scipy- pip install scipy 
numpy- pip install numpy
skimage-pip install scikit-image
matplotlib-python -m pip install -U matplotlib


-------------------------------------------------------------------------------------------------------------------------------------------
Download the code files and the .tif files
-------------------------------------------------------------------------------------------------------------------------------------------
Open the Image_gen_addn_ipynb first.


Make the following changes  :

1. Install tifffile.
	pip install tifffile 
	
2. Comment out-
	from google.colab import drive
	drive.mount('/content/drive/')
	These are required only if the file is run on Google Colab.
3.Paths
	Assuming you have downloaded the files to download folder.
	the directory would be 
	train_image_path-      ~/Downloads/train-volume.tif      # for train file	
	train_mask_path-       ~/Downloads/train-labels.tif        # for mask files
	test_path-                   ~/Downloads/test-volume.tif.      # for test files
	save_path-  "give a suitable location(Include the / after the path)" # save location
	All the directories go in the main function.
4. names.
	give appropriate names to the files.
	train_image_filename=   "name_of_your_choice_image.npy"
	train_mask_filename=    "name_of_your_choice_mask.npy"
	test_image_filename=    "name_of_your_choice_test.npy"
5.Image sizes.
	Set the output image size to the desired size range. Anywhere between (128x128) to the full size 	of the image. 
	output_shape= (height,width)
	If the output image needs to be of full size then toggle the "full_size" to True in the main function in 	the parameters passed to Augment(). If it is a smaller image set "full_size" to False.
	Size_of_test_image=(height,width) 	
6. Set the parameters.
	'tiff_file': True id .tif, False otherwise. To either load from tif images or other image formats
	'aug_ration': Number of images to be generated from each image
	'transforms': True if transforms are needed, False otherwise. if the image needs to have additional 			    transforms like flipping.
	'save': if True saves the numpy files to the desired location.

Run the file. 
----------------------------------------------------------------------------------------
Open the ADDN_package.ipynb 

Make the following changes:

1.Comment out-
	from google.colab import drive
	drive.mount('/content/drive/')
	These are required only if the file is run on Google Colab.

2. Verify that all the packages are installed  by running the imports cell.
	install if any package is missing.
	pip install <name of the package>

3. G to the block which has the data dictionary initialised:

	'data_path': path to the folder which has the data  generated by image generator      
        'train_image_name':name of the train image file
        'train_mask_name':name of the train mask file
        'val_image_name':name of the validation image file if present
        'val_mask_name':name of the validation mask file if if present 
        'test_image_name':name of the test file
        
        "weights_path_with_name":'path to the location where you want to save the weights/name of the             	file.hd5
        
        'save_train_images':path to location where you want to save the intermediate images generated 	during training 	to check the progress
        
        'savepath':path to loaction where you want to save the predicted output after training
        
        'depth': this decides the depth of the dilation block
        input_shape':  Input shape		(height,width)
        'output_shape': output shape
        'batch_size': batch size. If the model keep having memory error reduce the batch size. For 		512x512 set to 1 if running on Colab.
        
        'epochs': number of epochs
        'sample_interval': frequency of posting images generated during training 
        
        'df':  64, Discriminator feature factor. this decides the size of the layers of discriminator
        
        'patch': this is for stabalising the model. decided by imagesize/4. for 512-->128, 128-->32
        
        'generator_factor': feature factor for generator. this decides the size of the layers in densenet.
     
4. Initialise the the class by calling the ADDN class with (name for the run, the data). 
	x=ADDN(A,B)

5.  x.complie()

6. for training:
	call x.train(sample=True) if you want intermediate images or set sample=False.
	the function also outputs 3 lists for analysis for each epoch
7. x.test()
	to predict the test set.
