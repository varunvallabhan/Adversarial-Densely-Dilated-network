{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_gen_addn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3iOCmjC7mlZ",
        "colab_type": "code",
        "outputId": "ea3e47b0-5d3f-4f8a-b1c6-c8afe3b86e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4xpQejA9gF7",
        "colab_type": "code",
        "outputId": "cb34a975-d497-44e6-f0e8-67dbf5a216d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!pip install tifffile\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tifffile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/96/2fcac22c806145b34e682e03874b490ae09bc3e48013a0c77e590cd6be29/tifffile-2019.7.26-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from tifffile) (1.16.4)\n",
            "Installing collected packages: tifffile\n",
            "Successfully installed tifffile-2019.7.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFHUjGJJ7WnL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ea5599a-6426-46eb-ec21-9c48461e57f0"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import random\n",
        "import tifffile as tiff\n",
        "import cv2\n",
        "from keras.layers import Concatenate\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0p4qIds7p4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        ":Date: 2019-08-05\n",
        ":Version: 1\n",
        ":Authors:\n",
        "    - Varun Vallabhan\n",
        "\n",
        "This script is needed to create augmented images from a given set of images for \n",
        "creating a training dataset for ADDN and UNET. This is the updated version which \n",
        "not only uses the tiff file but also, can use other file formats like .bmp,.png,.jpg.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_images(folder):\n",
        "    \"\"\"\n",
        "    :folder: string\n",
        "    :rtype: List\n",
        "    This is the load function for images which are not in .tif file format. The function \n",
        "    load the the images in a list and and returns the list.\n",
        "    \"\"\"\n",
        "    images=[]\n",
        "    for filename in sorted(os.listdir(folder)):\n",
        "        \n",
        "        img = cv2.imread(os.path.join(folder,filename),0)\n",
        "        \n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "  \n",
        "def elastic_transform(image, alpha, sigma, alpha_affine, random_state=None):\n",
        "    \"\"\"\n",
        "    :image: numpy array\n",
        "    :alpha: numpy array\n",
        "    :sigma: numpy array\n",
        "    :alpha_affine: numpy array\n",
        "    \n",
        "    This function adds elastic transforms to the images. This uses affine transform to reorient the image to create the elastic effect.\n",
        "    \"\"\"\n",
        "    if random_state is None:\n",
        "        random_state = np.random.RandomState(None)\n",
        "\n",
        "    shape = image.shape\n",
        "    shape_size = shape[:2]\n",
        "\n",
        "    # Random affine\n",
        "    center_square = np.float32(shape_size) // 2\n",
        "    square_size = min(shape_size) // 3\n",
        "    pts1 = np.float32(\n",
        "        [center_square + square_size, [center_square[0] + square_size, center_square[1] - square_size],\n",
        "            center_square - square_size])\n",
        "    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
        "    M = cv2.getAffineTransform(pts1, pts2)\n",
        "    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
        "\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dz = np.zeros_like(dx)\n",
        "\n",
        "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
        "    indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
        "\n",
        "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
        "  \n",
        "  \n",
        "def random_transforms(items, nb_min=0, nb_max=5, rng=np.random):\n",
        "    \"\"\"\n",
        "    :items: numpy array\n",
        "    :nb_min: int\n",
        "    :nb_max: int\n",
        "    :rng: int\n",
        "    :rtype: numpy array\n",
        "    These are a bunch of transforms like rotating flipping which are used in augment function.\n",
        "    \"\"\"\n",
        "    all_transforms = [\n",
        "        lambda x: x,\n",
        "        lambda x: np.fliplr(x),\n",
        "        lambda x: np.flipud(x),\n",
        "        lambda x: np.rot90(x, 1),\n",
        "        lambda x: np.rot90(x, 2),\n",
        "        lambda x: np.rot90(x, 3),\n",
        "        # lambda x: add_noise(x),\n",
        "    ]\n",
        "    n = rng.randint(nb_min, nb_max + 1)\n",
        "    items_t = [item.copy() for item in items]\n",
        "    for _ in range(n):\n",
        "        idx = rng.randint(0, len(all_transforms))\n",
        "        transform = all_transforms[idx]\n",
        "        items_t = [transform(item) for item in items_t]\n",
        "    return items_t\n",
        "  \n",
        "  \n",
        "def add_noise(img):\n",
        "    \"\"\"\n",
        "    :img: numpy array\n",
        "    :rtype: numpy array\n",
        "    Adds noise to images at random pixels.\n",
        "    \"\"\"\n",
        "    for i in range(200):\n",
        "        temp_x = np.random.randint(0,img.shape[0])\n",
        "        temp_y = np.random.randint(0,img.shape[1])\n",
        "        img[temp_x][temp_y] = 255\n",
        "    return img\n",
        "\n",
        "  \n",
        "def normalization(imgs):\n",
        "    \"\"\"\n",
        "    :imgs:numpy array\n",
        "    :rtype: numpy array\n",
        "    Normalization of the images\n",
        "    \"\"\"\n",
        "    _mean, _std = np.mean(imgs), np.std(imgs)\n",
        "    normalize = lambda x: (x - _mean) / (_std + 1e-10)\n",
        "    return normalize(imgs)\n",
        "  \n",
        "  \n",
        "def tiff_img_reader(imgs_path,msks_path = None):\n",
        "    \"\"\"\n",
        "    :imgs_path: string\n",
        "    :msks_path: None in case of test/ string in case of train\n",
        "    :rtype: numpy array, numpy array (float32)\n",
        "    \n",
        "    tiff img reader segment to read tiff files. Requires tifffile library.\n",
        "    \"\"\"\n",
        "    imgs = tiff.imread(imgs_path).astype('float32') /255\n",
        "    if msks_path != None:\n",
        "        msks =tiff.imread(msks_path) // 255\n",
        "    else:\n",
        "        msks = None\n",
        "    return imgs,msks\n",
        "\n",
        "  \n",
        "def data_split(imgs_path,msks_path,tiff_file=True):\n",
        "    \"\"\"\n",
        "    :imgs_path: string\n",
        "    :msks_path: string\n",
        "    :tiff_file: bool\n",
        "    :rtype: numpy array,numpy array,numpy array,numpy array (float32)\n",
        "    \n",
        "    Splits data into train and validation before it is sent for augmentation.\n",
        "    \"\"\"\n",
        "    if tiff_file==True:\n",
        "        imgs, msks =  tiff_img_reader(imgs_path,msks_path)\n",
        "    else:\n",
        "        imgs=np.asarray(load_images(imgs_path))/255.\n",
        "        msks=np.asarray(load_images(msks_path))/255.\n",
        "    idxs = random.sample(range(imgs.shape[0]),imgs.shape[0] // 5)\n",
        "    rest = [i for i in range(imgs.shape[0]) if i not in idxs]\n",
        "    imgs_val = imgs[idxs]\n",
        "    msks_val = msks[idxs]\n",
        "    imgs_trn = imgs[rest]\n",
        "    msks_trn = msks[rest]\n",
        "    return imgs_trn,msks_trn,imgs_val,msks_val\n",
        "\n",
        "  \n",
        "def Augment(imgs, msks, output_shape, aug_ration=10, full_size=False,transform = False, rng=np.random):\n",
        "    \n",
        "    '''\n",
        "    :imgs: float\n",
        "    :msks: uint8\n",
        "    :output_shape:(int,int)\n",
        "    :aug_ration: int\n",
        "    :full_size: bool\n",
        "    :transform:bool\n",
        "    :rng:int\n",
        "    :rtype: numpy array,numpy array (float32)\n",
        "    \n",
        "    The images are first cropped to desired shape and size accoring to the output shape requested \n",
        "    and then they are subjected to elastic transformationa and then they are randomly flipped or \n",
        "    rotated using the random transform function. If the images are not to be cropped set full_size to False which is the default\n",
        "    and if only elastic transformations are required set the transform to False which will prevent random transformation. aug_ration \n",
        "    decides the number of augmented images per actual image. \n",
        "    '''\n",
        "    img_len, H, W = imgs.shape\n",
        "    wdw_H,wdw_W = output_shape\n",
        "    img_batch = np.zeros((img_len*aug_ration,) + output_shape, dtype=np.float32)\n",
        "    msk_batch = np.zeros((img_len*aug_ration,) + output_shape, dtype=np.uint8)\n",
        "    batch_idx = 0\n",
        "    for img_idx in range(img_len):\n",
        "        print('original image number:%d output shape:(%d,%d)'%(img_idx,wdw_H,wdw_W))\n",
        "        for num in range(aug_ration):\n",
        "            if full_size:\n",
        "              im = imgs[img_idx]\n",
        "              im_mask = msks[img_idx]\n",
        "            else:\n",
        "              \n",
        "              y0, x0 = rng.randint(0, H - wdw_H), rng.randint(0, W - wdw_W)\n",
        "              \n",
        "              y1, x1 = y0 + wdw_H, x0 + wdw_W\n",
        "              \n",
        "              im = imgs[img_idx][y0:y1, x0:x1]\n",
        "              im_mask = msks[img_idx][y0:y1, x0:x1]\n",
        "            #### elastic  transform\n",
        "            if np.random.randint(0, 10) > 7:\n",
        "                im_merge = np.concatenate((im[..., None], im_mask[..., None]), axis=2)\n",
        "                im_merge_t = elastic_transform(im_merge, im_merge.shape[1] * 2, im_merge.shape[1] * 0.08,im_merge.shape[1] * 0.08)\n",
        "                im_t = im_merge_t[..., 0]\n",
        "                im_mask_t = im_merge_t[..., 1]\n",
        "                img_batch[batch_idx] = im_t\n",
        "                msk_batch[batch_idx] = im_mask_t\n",
        "            else:\n",
        "                img_batch[batch_idx] = im\n",
        "                msk_batch[batch_idx] = im_mask\n",
        "            if transform:\n",
        "                [img_batch[batch_idx], msk_batch[batch_idx]] = random_transforms(\n",
        "                    [img_batch[batch_idx], msk_batch[batch_idx]])\n",
        "            batch_idx += 1\n",
        "    img_batch = img_batch[:, :, :, np.newaxis]\n",
        "    msk_batch = msk_batch[:, :, :, np.newaxis]\n",
        "    # tiff.imsave('test.tif',np.uint8(img_batch[0]*255))\n",
        "    return img_batch,msk_batch\n",
        "  \n",
        "  \n",
        "def save_npy(data, name, npy_path):\n",
        "    \"\"\"\n",
        "    :data: numpy array\n",
        "    :name: string\n",
        "    :npy_path: string\n",
        "    \n",
        "    This saves the augmented images in a numpy file.\n",
        "    \"\"\"\n",
        "    print (\"saving npy data...\")\n",
        "    np.save(npy_path+'/'+name, data)\n",
        "    print (\"Data %s saved in root: %s.\" % (name, npy_path))\n",
        "    \n",
        "    \n",
        "def generate_test(path,tiff_file=True,height=128,width=128):\n",
        "  \"\"\"\n",
        "  :path: string\n",
        "  :tiff_file: bool\n",
        "  :height: int\n",
        "  :width: int\n",
        "  :rtype: numpy array\n",
        "  \n",
        "  This generates the test image of the requested size.\n",
        "  \"\"\"\n",
        "  if tiff_file:\n",
        "    imgs_tst,_ = tiff_img_reader(path)\n",
        "  else:\n",
        "    imgs_tst=np.asarray(load_images(path))/255. \n",
        "  imgs_tst = imgs_tst[:,:height,:width,np.newaxis]  \n",
        "  return imgs_tst\n",
        "  \n",
        "  \n",
        "def main(config):\n",
        "  \"\"\"\n",
        "  :config: dict\n",
        "  \n",
        "  This funtions calls all the funtions in order to read, split, augment and save the data. \n",
        "  the parameters are passed in a config dictionary which includes the paths and modes that are needed for generating the images \n",
        "  \"\"\"\n",
        "  imgs_trn, msks_trn, imgs_val, msks_val = data_split(config['train_image_path'],config['train_mask_path'],tiff_file=config[\"tiff_file\"])\n",
        "  print('generating training images')\n",
        "  img_batch, msk_batch = Augment(imgs=imgs_trn,msks= msks_trn,output_shape=config['output_shape'],\\\n",
        "                                 aug_ration=config['aug_ration'],transform=config['transform'],full_size=config['full_size'])\n",
        "  print ('generating validation images')\n",
        "  img_val, msk_val = Augment(imgs=imgs_val,msks= msks_val,output_shape=config['output_shape'],aug_ration=config['aug_ration'],\\\n",
        "                             transform=config['transform'],full_size=config['full_size'])\n",
        "  imgs_tst=generate_test(config['test_path'],tiff_file=config['tiff_file'],height=config['output_shape'][0],width=config['output_shape'][1])\n",
        "  if config['save']:\n",
        "    save_npy(imgs_tst, config['test_image_filename'], config['save_path'])\n",
        "    save_npy(img_batch,config['train_image_filename'],config['save_path'])\n",
        "    save_npy(msk_batch, config['train_mask_filename'], config['save_path'])\n",
        "    save_npy(img_val,config['validation_image_filename'],config['save_path'])\n",
        "    save_npy(msk_val, config['validation_mask_filename'], config['save_path'])\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO5sokkD7yTp",
        "colab_type": "code",
        "outputId": "00087023-a8db-4000-c240-d6100703b8a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "config={\n",
        "'train_image_path':location of the training images\n",
        "'train_mask_path':location of the training label\n",
        "'full_size': If we need the maximum size\n",
        "'tiff_file': To either load from tif images or other image formats\n",
        "'aug_ration': Number of images to be generated from each image\n",
        "'transforms': if the image needs to have additional transforms like flipping.\n",
        "'test_path':location of testing file in case of tiff. Location of the test folder otherwise\n",
        "'train_image_filename':name for the training images\n",
        "'train_mask_filename':name for the training mask\n",
        "'test_image_filename':name for testing images\n",
        "'validation_image_filename':name for the validation images\n",
        "'validation_mask_filename':'name for the validation masks\n",
        "'save_path':loaction for saving the data\n",
        "'save': if True saves the numpy files to the desired location.\n",
        "'output_shape':(512,512) #if full size then irrelevent. Set fullsize is to true, If the image is not downsized.\n",
        "'Size_of_test_image':(512,512)  Output size of the test image\n",
        "}\n",
        "\n",
        "#'train_image_path':'drive/My Drive/GAN_seg/ADDN-master/data/train-volume.tif',\n",
        "#'train_mask_path':'drive/My Drive/GAN_seg/ADDN-master/data/train-labels.tif',\n",
        "#'test_path':'drive/My Drive/GAN_seg/ADDN-master/data/test-volume.tif',\n",
        "#'save_path':'drive/My Drive/GAN_seg/ADDN-master/',\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "data={\n",
        "      'train_image_path':'drive/My Drive/test/images',\n",
        "      'train_mask_path':'drive/My Drive/test/label',\n",
        "      'full_size':False,\n",
        "      'tiff_file':False,\n",
        "      'aug_ration': 100 ,\n",
        "      'transform': True,\n",
        "      \n",
        "      'test_path':'drive/My Drive/test/test',\n",
        "      'train_image_filename':'new_img_trn.npy',\n",
        "      'train_mask_filename':'new_msk_trn.npy',\n",
        "      'test_image_filename':'img_tst.npy',\n",
        "      'validation_image_filename':'new_img_val.npy',\n",
        "      'validation_mask_filename':'new_msk_val.npy',\n",
        "      \n",
        "      'save_path':'drive/My Drive/test/',\n",
        "      'save':True,\n",
        "      'output_shape':(128,128), #if full size then irrelevent fullsize is set to true.\n",
        "      \n",
        "}\n",
        "\n",
        "\n",
        "main(data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generating training images\n",
            "original image number:0 output shape:(128,128)\n",
            "original image number:1 output shape:(128,128)\n",
            "original image number:2 output shape:(128,128)\n",
            "original image number:3 output shape:(128,128)\n",
            "original image number:4 output shape:(128,128)\n",
            "original image number:5 output shape:(128,128)\n",
            "original image number:6 output shape:(128,128)\n",
            "original image number:7 output shape:(128,128)\n",
            "original image number:8 output shape:(128,128)\n",
            "original image number:9 output shape:(128,128)\n",
            "original image number:10 output shape:(128,128)\n",
            "original image number:11 output shape:(128,128)\n",
            "original image number:12 output shape:(128,128)\n",
            "original image number:13 output shape:(128,128)\n",
            "original image number:14 output shape:(128,128)\n",
            "original image number:15 output shape:(128,128)\n",
            "original image number:16 output shape:(128,128)\n",
            "original image number:17 output shape:(128,128)\n",
            "original image number:18 output shape:(128,128)\n",
            "original image number:19 output shape:(128,128)\n",
            "original image number:20 output shape:(128,128)\n",
            "original image number:21 output shape:(128,128)\n",
            "original image number:22 output shape:(128,128)\n",
            "original image number:23 output shape:(128,128)\n",
            "generating validation images\n",
            "original image number:0 output shape:(128,128)\n",
            "original image number:1 output shape:(128,128)\n",
            "original image number:2 output shape:(128,128)\n",
            "original image number:3 output shape:(128,128)\n",
            "original image number:4 output shape:(128,128)\n",
            "original image number:5 output shape:(128,128)\n",
            "saving npy data...\n",
            "Data img_tst.npy saved in root: drive/My Drive/test/.\n",
            "saving npy data...\n",
            "Data new_img_trn.npy saved in root: drive/My Drive/test/.\n",
            "saving npy data...\n",
            "Data new_msk_trn.npy saved in root: drive/My Drive/test/.\n",
            "saving npy data...\n",
            "Data new_img_val.npy saved in root: drive/My Drive/test/.\n",
            "saving npy data...\n",
            "Data new_msk_val.npy saved in root: drive/My Drive/test/.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}