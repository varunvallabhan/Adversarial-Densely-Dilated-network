{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_gen_addn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3iOCmjC7mlZ",
        "colab_type": "code",
        "outputId": "e45cfb19-981e-4a7e-b717-cfea41a4fd25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4xpQejA9gF7",
        "colab_type": "code",
        "outputId": "78201e87-0438-4f55-91f2-aedda23c6f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install tifffile\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.6/dist-packages (2019.7.26)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from tifffile) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFHUjGJJ7WnL",
        "colab_type": "code",
        "outputId": "1e972aed-8d39-4b3e-a8b0-03c600a6f3d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import random\n",
        "import tifffile as tiff\n",
        "import cv2\n",
        "from keras.layers import Concatenate\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0p4qIds7p4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_montage(imgs_path, msks_path, nb_rows, nb_cols, rng):\n",
        "    '''Reads the images and masks and arranges them in a montage for sampling in training.'''\n",
        "    imgs, msks = tiff.imread(imgs_path), tiff.imread(msks_path) / 255\n",
        "    montage_imgs = np.empty((nb_rows * imgs.shape[1], nb_cols * imgs.shape[2]), dtype=np.float32)\n",
        "    montage_msks = np.empty((nb_rows * imgs.shape[1], nb_cols * imgs.shape[2]), dtype=np.int8)\n",
        "    idxs = np.arange(imgs.shape[0])\n",
        "    rng.shuffle(idxs)\n",
        "    idxs = iter(idxs)\n",
        "    for y0 in range(0, montage_imgs.shape[0], imgs.shape[1]):\n",
        "        for x0 in range(0, montage_imgs.shape[1], imgs.shape[2]):\n",
        "            y1, x1 = y0 + imgs.shape[1], x0 + imgs.shape[2]\n",
        "            idx = next(idxs)\n",
        "            montage_imgs[y0:y1, x0:x1] = imgs[idx]\n",
        "            montage_msks[y0:y1, x0:x1] = msks[idx]\n",
        "    return montage_imgs, montage_msks\n",
        "def load_montage_data(imgs_trn,msks_trn,row_trn,imgs_val, msks_val,col_trn,row_val,col_val):\n",
        "    Imgs_trn, Msks_trn = get_data_montage(imgs_trn, msks_trn,nb_rows=row_trn, nb_cols=col_trn, rng=np.random)\n",
        "    Imgs_val, Msks_val = get_data_montage(imgs_val, msks_val,nb_rows=row_val, nb_cols=col_val, rng=np.random)\n",
        "    return Imgs_trn,Msks_trn,Imgs_val,Msks_val\n",
        "def elastic_transform(image, alpha, sigma, alpha_affine, random_state=None):\n",
        "    if random_state is None:\n",
        "        random_state = np.random.RandomState(None)\n",
        "\n",
        "    shape = image.shape\n",
        "    shape_size = shape[:2]\n",
        "\n",
        "    # Random affine\n",
        "    center_square = np.float32(shape_size) // 2\n",
        "    square_size = min(shape_size) // 3\n",
        "    pts1 = np.float32(\n",
        "        [center_square + square_size, [center_square[0] + square_size, center_square[1] - square_size],\n",
        "            center_square - square_size])\n",
        "    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
        "    M = cv2.getAffineTransform(pts1, pts2)\n",
        "    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
        "\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dz = np.zeros_like(dx)\n",
        "\n",
        "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
        "    indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
        "\n",
        "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
        "def random_transforms(items, nb_min=0, nb_max=5, rng=np.random):\n",
        "    all_transforms = [\n",
        "        lambda x: x,\n",
        "        lambda x: np.fliplr(x),\n",
        "        lambda x: np.flipud(x),\n",
        "        lambda x: np.rot90(x, 1),\n",
        "        lambda x: np.rot90(x, 2),\n",
        "        lambda x: np.rot90(x, 3),\n",
        "        # lambda x: add_noise(x),\n",
        "    ]\n",
        "    n = rng.randint(nb_min, nb_max + 1)\n",
        "    items_t = [item.copy() for item in items]\n",
        "    for _ in range(n):\n",
        "        idx = rng.randint(0, len(all_transforms))\n",
        "        transform = all_transforms[idx]\n",
        "        items_t = [transform(item) for item in items_t]\n",
        "    return items_t\n",
        "def add_noise(img):\n",
        "    for i in range(200):\n",
        "        temp_x = np.random.randint(0,img.shape[0])\n",
        "        temp_y = np.random.randint(0,img.shape[1])\n",
        "        img[temp_x][temp_y] = 255\n",
        "    return img\n",
        "#########################################################################################\n",
        "def normalization(imgs):\n",
        "    #Normalization\n",
        "    _mean, _std = np.mean(imgs), np.std(imgs)\n",
        "    normalize = lambda x: (x - _mean) / (_std + 1e-10)\n",
        "    return normalize(imgs)\n",
        "def tiff_img_reader(imgs_path,msks_path = None):\n",
        "    ##tiff img reader\n",
        "    imgs = tiff.imread(imgs_path).astype('float32') /255\n",
        "    if msks_path != None:\n",
        "        msks =tiff.imread(msks_path) // 255\n",
        "    else:\n",
        "        msks = None\n",
        "    return imgs,msks\n",
        "def data_split(imgs_path,msks_path):\n",
        "    imgs, msks =  tiff_img_reader(imgs_path,msks_path)\n",
        "    idxs = random.sample(range(imgs.shape[0]),imgs.shape[0] // 5)\n",
        "    rest = [i for i in range(imgs.shape[0]) if i not in idxs]\n",
        "    imgs_val = imgs[idxs]\n",
        "    msks_val = msks[idxs]\n",
        "    imgs_trn = imgs[rest]\n",
        "    msks_trn = msks[rest]\n",
        "    return imgs_trn,msks_trn,imgs_val,msks_val\n",
        "\n",
        "def Augment(imgs, msks, output_shape, aug_ration=10, full_size=False,transform = False, rng=np.random):\n",
        "    #### imgs: dtype float32  msks: dtype uint8 ####\n",
        "    img_len, H, W = imgs.shape\n",
        "    wdw_H,wdw_W = output_shape\n",
        "    img_batch = np.zeros((img_len*aug_ration,) + output_shape, dtype=np.float32)\n",
        "    msk_batch = np.zeros((img_len*aug_ration,) + output_shape, dtype=np.uint8)\n",
        "    batch_idx = 0\n",
        "    for img_idx in range(img_len):\n",
        "        print(img_idx)\n",
        "        for num in range(aug_ration):\n",
        "            if full_size:\n",
        "              im = imgs[img_idx]\n",
        "              im_mask = msks[img_idx]\n",
        "            else:\n",
        "              \n",
        "              y0, x0 = rng.randint(0, H - wdw_H), rng.randint(0, W - wdw_W)\n",
        "              \n",
        "              y1, x1 = y0 + wdw_H, x0 + wdw_W\n",
        "              \n",
        "              im = imgs[img_idx][y0:y1, x0:x1]\n",
        "              im_mask = msks[img_idx][y0:y1, x0:x1]\n",
        "            #### elastic  transform\n",
        "            if np.random.randint(0, 10) > 7:\n",
        "                im_merge = np.concatenate((im[..., None], im_mask[..., None]), axis=2)\n",
        "                im_merge_t = elastic_transform(im_merge, im_merge.shape[1] * 2, im_merge.shape[1] * 0.08,im_merge.shape[1] * 0.08)\n",
        "                im_t = im_merge_t[..., 0]\n",
        "                im_mask_t = im_merge_t[..., 1]\n",
        "                img_batch[batch_idx] = im_t\n",
        "                msk_batch[batch_idx] = im_mask_t\n",
        "            else:\n",
        "                img_batch[batch_idx] = im\n",
        "                msk_batch[batch_idx] = im_mask\n",
        "            if transform:\n",
        "                [img_batch[batch_idx], msk_batch[batch_idx]] = random_transforms(\n",
        "                    [img_batch[batch_idx], msk_batch[batch_idx]])\n",
        "            batch_idx += 1\n",
        "    img_batch = img_batch[:, :, :, np.newaxis]\n",
        "    msk_batch = msk_batch[:, :, :, np.newaxis]\n",
        "    # tiff.imsave('test.tif',np.uint8(img_batch[0]*255))\n",
        "    return img_batch,msk_batch\n",
        "def save_npy(data, name, npy_path):\n",
        "    print (\"saving npy data...\")\n",
        "    np.save(npy_path+name, data)\n",
        "    print (\"Data %s saved in root: %s.\" % (name, npy_path))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO5sokkD7yTp",
        "colab_type": "code",
        "outputId": "a8662728-6851-4348-b71f-d1d52e9bd4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def main(config):\n",
        "\n",
        "  imgs_trn, msks_trn, imgs_val, msks_val = data_split(config['train_image_path'],config['train_mask_path'])\n",
        "  \n",
        "  img_batch, msk_batch = Augment(imgs=imgs_trn,msks= msks_trn,output_shape=config['output_shape'],aug_ration=100,transform=True,full_size=True)\n",
        "  \n",
        "  save_npy(img_batch,config['train_image_filename'],config['save_path'])\n",
        "  save_npy(msk_batch, config['train_mask_filename'], config['save_path'])\n",
        "  imgs_tst,_ = tiff_img_reader(config['test_path'])  \n",
        "  imgs_tst = imgs_tst[:,:config['Size_of_test_image'][0],:config['Size_of_test_image'][1],np.newaxis]  \n",
        "  save_npy(imgs_tst, config['test_image_filename'], config['save_path'])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "data={\n",
        "'train_image_path':location of the training images\n",
        "'train_mask_path':location of the training label\n",
        "'test_path':location of testing file\n",
        "'train_image_filename':name for the training images\n",
        "'train_mask_filename':name for the training mask\n",
        "'test_image_filename':name for testing images\n",
        "'save_path':loaction for saving the data\n",
        "'output_shape':(512,512) #if full size then irrelevent. Set fullsize is to true, If the image is not downsized.\n",
        "'Size_of_test_image':(512,512)  Output size of the test image\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "data={'train_image_path':'drive/My Drive/GAN_seg/ADDN-master/data/train-volume.tif',\n",
        "      'train_mask_path':'drive/My Drive/GAN_seg/ADDN-master/data/train-labels.tif',\n",
        "      'test_path':'drive/My Drive/GAN_seg/ADDN-master/data/test-volume.tif',\n",
        "      'train_image_filename':'new_img_trn.npy',\n",
        "      'train_mask_filename':'new_msk_trn.npy',\n",
        "      'test_image_filename':'img_tst.npy',\n",
        "      'save_path':'drive/My Drive/GAN_seg/ADDN-master/',\n",
        "      'output_shape':(512,512), #if full size then irrelevent fullsize is set to true.\n",
        "      'Size_of_test_image':(512,512),\n",
        "}\n",
        "\n",
        "\n",
        "main(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}