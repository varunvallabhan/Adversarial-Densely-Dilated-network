{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADDN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTdFdi8rEUnr",
        "colab_type": "code",
        "outputId": "411ce167-5988-4936-8aea-216a977f0483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#connecting to the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzEIKA9MIDII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Headers and libraries\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "import keras.backend as K\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "from os import path, makedirs\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.misc import imsave\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import random\n",
        "import skimage.io as io\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNswDOLxIQqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This class deals with all the data related calls. The class is called by DataLoader(Path to the folder where you have the data,\n",
        "name of the train file, name of the train mask, name of validation image file, name of the validation mask file, name of the test file)\n",
        "All the files are numpy arrarys stored in .npy format\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, dataset,name_train='',name_mask='',val_img='',val_msk='',test=''):\n",
        "        self.dataset = dataset\n",
        "        self.image=name_train\n",
        "        self.mask=name_mask\n",
        "        self.val_msk=val_msk\n",
        "        self.val_img=val_img\n",
        "        self.tst=test\n",
        "    def load_test(self):\n",
        "        return np.load(dataset+test)\n",
        "      \n",
        "    def load_npy_data(self,flag):\n",
        "        imgs_trn = np.load(self.dataset+'/' + self.image)\n",
        "        msks_trn = np.load(self.dataset +'/'+ self.mask)\n",
        "        imgs_val = np.load(self.dataset +'/'+ self.val_img)\n",
        "        msks_val = np.load(self.dataset +'/'+ self.val_msk)\n",
        "        imgs_tst = np.load(self.dataset +'/'+ self.tst)\n",
        "        if flag == \"train\":\n",
        "            return imgs_trn[:1200],msks_trn[:1200]\n",
        "        elif flag == \"val\":\n",
        "            return imgs_val,msks_val\n",
        "        elif flag == \"submit\":\n",
        "            return imgs_tst\n",
        "\n",
        "    def load_batch(self, batch_size=1):\n",
        "        imgs_trn = np.load(self.dataset+'/' + self.image)\n",
        "        msks_trn = np.load(self.dataset+'/' + self.mask)\n",
        "        self.n_batches = int(imgs_trn.shape[0] / batch_size)\n",
        "        \n",
        "        for i in range(self.n_batches - 1):\n",
        "            imgs =imgs_trn[i * batch_size:(i + 1) * batch_size]\n",
        "            labels = msks_trn[i * batch_size:(i + 1) * batch_size]\n",
        "            yield imgs, labels\n",
        "\n",
        "    def load_img(self, batch_size=1):\n",
        "        imgs_val = np.load(self.dataset+'/'+ self.image)\n",
        "        msks_val = np.load(self.dataset +'/'+ self.mask)\n",
        "        batch_images = random.sample(range(imgs_val.shape[0]), batch_size)\n",
        "        return imgs_val[batch_images],msks_val[batch_images]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulKUaXeAIUKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1.0\n",
        "    y_true_flat = K.flatten(y_true)\n",
        "    y_pred_flat = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_flat * y_pred_flat)\n",
        "    return (2.0 * intersection + smooth) / (K.sum(y_true_flat) + K.sum(y_pred_flat) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - 1.0 * dice_coef(y_true, y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIUbTordIWsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#network\n",
        "\"\"\"\n",
        "The get_densenet takes input shape and builds a dense dilated network. \n",
        "The feature size and dpeth are set to 4 which can be reduced in case of lower computational power.\n",
        "the build_discriminator function takes input size and discriminator factor as input the value DF is then used to determine the size of the layers.\n",
        "\"\"\"\n",
        "def get_densenet(input_shape,feature=48):\n",
        "    K.set_image_dim_ordering('tf')\n",
        "    x = inputs = Input(shape=input_shape, dtype='float32')\n",
        "    x = Conv2D(feature, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = dc_0_out = dense_block(x)\n",
        "    x = transition_Down(x, feature*2)\n",
        "    x = dc_1_out = dense_block(x)\n",
        "    x = transition_Down(x, feature*3)\n",
        "    x = dc_2_out = dense_block(x)\n",
        "    x = transition_Down(x, feature*4)\n",
        "    x = dc_3_out = dense_block(x)\n",
        "    x = transition_Down(x, feature*5)\n",
        "    x = dense_block(x)\n",
        "    x = transition_Up(x, feature)\n",
        "    x = concatenate([x, dc_3_out])\n",
        "    x = dense_block(x)\n",
        "    x = transition_Up(x, feature)\n",
        "    x = concatenate([x, dc_2_out])\n",
        "    x = dense_block(x)\n",
        "    x = transition_Up(x, feature)\n",
        "    x = concatenate([x, dc_1_out])\n",
        "    x = dense_block(x)\n",
        "    x = transition_Up(x, feature)\n",
        "    x = concatenate([x, dc_0_out])\n",
        "    x = dense_block(x)\n",
        "    x = Conv2D(1, 1, activation='sigmoid')(x)\n",
        "    net = Model(inputs=inputs, outputs=x)\n",
        "    return net\n",
        "\n",
        "def dense_block(input_layer, features=12, depth=4,temperature=1.0, padding='same', batchnorm=False,dropout=0.2):\n",
        "    inputs = x = input_layer\n",
        "    maps = [inputs]\n",
        "    dilation_rate = 1\n",
        "    kernel_size = (3, 3)\n",
        "    for n in range(depth):\n",
        "        x0 = x\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2D(features, kernel_size, dilation_rate=dilation_rate,\n",
        "                   padding=padding, kernel_initializer='he_normal')(x)\n",
        "        x = Dropout(dropout)(x)\n",
        "        maps.append(x)\n",
        "        if n!= depth-1:\n",
        "            x = Concatenate()([x0, x])\n",
        "        else:\n",
        "            x = Concatenate()(maps)\n",
        "        dilation_rate *= 2\n",
        "    return x\n",
        "\n",
        "\n",
        "def transition_Down(input_layer,features,kernel_size=(3,3), padding='same',dropout=0.2):\n",
        "    x = BatchNormalization()(input_layer)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(features, kernel_size,\n",
        "                   padding=padding, kernel_initializer='he_normal')(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = MaxPooling2D(2,2)(x)\n",
        "    return x\n",
        "\n",
        "def transition_Up(input_layer, feature, kernel_size=(3,3),stride=2):\n",
        "    x = Conv2DTranspose(feature, 2, strides=stride, activation='relu', kernel_initializer='he_normal')(input_layer)\n",
        "    return x\n",
        "\n",
        "def build_discriminator(img_shape,df):\n",
        "    def d_layer(layer_input, filters, f_size=4, bn=True):\n",
        "        \"\"\"Discriminator layer\"\"\"\n",
        "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "        d = LeakyReLU(alpha=0.2)(d)\n",
        "        if bn:\n",
        "            d = BatchNormalization(momentum=0.8)(d)\n",
        "        return d\n",
        "    def layer (layer_input, filters, f_size=4, bn=True):\n",
        "        d = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(layer_input)\n",
        "        d = LeakyReLU(alpha=0.2)(d)\n",
        "        if bn:\n",
        "            d = BatchNormalization(momentum=0.8)(d)\n",
        "        return d\n",
        "    img_A = Input(shape=img_shape)\n",
        "    img_B = Input(shape=img_shape)\n",
        "\n",
        "    # Concatenate image and conditioning image by channels to produce input\n",
        "    combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
        "    d1 = d_layer(combined_imgs, df, bn=False)\n",
        "    d2 = d_layer(d1, df*2)\n",
        "    d3 = layer(d2, df*4)\n",
        "    # d4 = layer(d3, df*8)\n",
        "    validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d3)\n",
        "    model = Model([img_A, img_B], validity)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAHqzjUwIbPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#main\n",
        "\n",
        "class ADDN():\n",
        "    def __init__(self,checkpoint_name,data):\n",
        "        ### Configurations\n",
        "        self.config = data\n",
        "        # Calculate output shape of D (PatchGAN)\n",
        "        self.img_rows = int(self.config['input_shape'][0])\n",
        "        self.disc_patch = (self.config['patch'], self.config['patch'], 1)\n",
        "        self.data_loader = DataLoader(dataset=self.config['data_path'],name_train=self.config['train_image_name'],name_mask=self.config['train_mask_name'],test=self.config['test_image_name'])\n",
        "        self.checkpoint_name = checkpoint_name\n",
        "\n",
        "        self.generator = None\n",
        "        self.discriminator = None\n",
        "        self.combined = None\n",
        "        self.imgs_trn = None\n",
        "        self.msks_trn = None\n",
        "        self.imgs_val = None\n",
        "        self.msks_val = None\n",
        "        log_path = 'Graph/addn'\n",
        "        self.callback = TensorBoard(log_path)\n",
        "        return\n",
        "\n",
        "    @property\n",
        "    def checkpoint_path(self):\n",
        "        return self.config['data_path']+'%s' % (self.checkpoint_name)\n",
        "\n",
        "    def compile(self):\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = build_discriminator(self.config['input_shape'], self.config['df'])\n",
        "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
        "        self.discriminator.summary()\n",
        "        # Build the generator\n",
        "        self.generator = get_densenet(self.config['input_shape'],self.config['generator_factor'])\n",
        "        self.generator.summary()\n",
        "        #self.generator =get_generator(self.config['input_shape'])\n",
        "        img = Input(shape=self.config['input_shape'])\n",
        "        label = Input(shape=self.config['input_shape'])\n",
        "        seg = self.generator(img)\n",
        "        self.discriminator.trainable = False\n",
        "        valid = self.discriminator([seg, img])\n",
        "        self.combined = Model(inputs=[label, img], outputs=[valid, seg])\n",
        "        self.combined.compile(loss=['mse',dice_coef_loss], loss_weights=[1, 100], optimizer=optimizer)\n",
        "        #self.callback.set_model(self.generator)\n",
        "        return\n",
        "\n",
        "    def train(self, sample=False):\n",
        "        start_time = datetime.datetime.now()\n",
        "        # Adversarial loss ground truths\n",
        "        valid = np.ones((self.config['batch_size'],) + self.disc_patch)\n",
        "        fake = np.zeros((self.config['batch_size'],) + self.disc_patch)\n",
        "        gen_loss=[]\n",
        "        dis_loss=[]\n",
        "        acc=[]\n",
        "        for epoch in range(self.config['epochs']):\n",
        "            for batch_i, (imgs, labels) in enumerate(self.data_loader.load_batch(self.config['batch_size'])):\n",
        "                # Condition on B and generate a translated version\n",
        "\n",
        "                # Train the discriminators (original images = real / generated = Fake)\n",
        "                dl=100000\n",
        "                segs = self.generator.predict(imgs)\n",
        "                d_loss_real = self.discriminator.train_on_batch([labels, imgs], valid)\n",
        "                d_loss_fake = self.discriminator.train_on_batch([segs, imgs], fake)\n",
        "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "                # Train the generators\n",
        "                g_loss = self.combined.train_on_batch([labels, imgs], [valid, labels])\n",
        "                elapsed_time = datetime.datetime.now() - start_time\n",
        "                # Plot the progress\n",
        "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, self.config['epochs'],\n",
        "                                                                        batch_i, self.data_loader.n_batches,\n",
        "                                                                        d_loss[0], 100*d_loss[1],\n",
        "                                                                        g_loss[0],\n",
        "                                                                        elapsed_time))\n",
        "                if dl>d_loss[0]:\n",
        "                  self.generator.save_weights(self.config['weights_path_with_name'])\n",
        "                  dl=d_loss[0]\n",
        "                  ac=acc\n",
        "\n",
        "                # If at save interval => save generated image samples\n",
        "                if sample == True:\n",
        "                    if batch_i % self.config['sample_interval'] == 0:\n",
        "                        self.sample_images(epoch, batch_i)\n",
        "            train_names = 'train_loss'\n",
        "            \n",
        "            gen_loss.append(g_loss)\n",
        "            dis_loss.append(d_loss)\n",
        "            acc.append(100*d_loss[1])\n",
        "        np.save(self.config['savepath']+'/discriminator.npy',dis_loss)\n",
        "        np.save(self.config['savepath']+'/generator.npy',gen_loss)\n",
        "        np.save(self.config['savepath']+'/accuracy.npy',acc)\n",
        "            \n",
        "        print(dl,ac)\n",
        "        return [gen_loss,dis_loss,acc]\n",
        "    def predict(self, imgs):\n",
        "        return self.generator.predict(imgs)\n",
        "\n",
        "    def sample_images(self, epoch, batch_i):\n",
        "        # r, c = 3, 3\n",
        "        imgs, labels = self.data_loader.load_img(batch_size=1)\n",
        "        segs = self.predict(imgs)\n",
        "        print (segs.shape)\n",
        "        cv2.imwrite(self.config['save_train_images']+'/%d_%d.bmp' % (epoch, batch_i), segs[0][:, :, 0]*255)\n",
        "    def test(self):\n",
        "          imgtst=self.data_loader.load_test()\n",
        "          #print(imgtst.shape) \n",
        "\n",
        "          results=self.generator.predict(imgtst,batch_size=2, verbose=1)\n",
        "\n",
        "          def saveResult(self,npyfile):\n",
        "              for i in range(numpyfile.shape[0]):\n",
        "                  cv2.imwrite(self.config['save_path']+\"%d_predict_vm.png\"%i,npyfile[i]*255)\n",
        "          self.saveResult(self.config['savepath'],results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0_r7xkya6p8",
        "colab_type": "code",
        "outputId": "5894c64c-b1b5-45aa-b1d3-2b3a0cb52862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "THe ADDN class is where training and testing is done. \n",
        "COmpile is where the model is initialised and compiled and train module trains the GAN.\n",
        "Sample images is used to store imaged while training and saveResult is used to save predicted output during testing.\n",
        "\n",
        "\n",
        "\n",
        "data={\n",
        "        'data_path': path to the folder which has the data        \n",
        "        'train_image_name':name of the train image file\n",
        "        'train_mask_name':name of the train mask file\n",
        "        'val_image_name':name of the validation image file\n",
        "        'val_mask_name':name of the validation mask file\n",
        "        'test_image_name':name of the test file\n",
        "        \"weights_path_with_name\":'path to the loaction where you want to save the weights/nameof the file.hd5\n",
        "        'save_train_images':path to loaction where you want to save the images generated during training to check the progress\n",
        "        'savepath':path to loaction where you want to save the predicted output after training\n",
        "        'input_shape': Input shape\n",
        "        'output_shape': output shape\n",
        "        'batch_size': batch size. If the model keep having memory error reduce the batch size. For 512x512 set to 1 if running on Colab.\n",
        "        'epochs': number of epochs\n",
        "        'sample_interval': frequency of posting images generated during training \n",
        "        'df':64, Discriminator factor. this decides the size of the layers of discriminator\n",
        "        'patch':this is  for stabalising the model. decided by imagesize/4. for 512-->128, 128-->32\n",
        "        'feature_factor': feature factor for generator. \n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "data={\n",
        "        'data_path': \"drive/My Drive/GAN_seg/ADDN-master/data\",\n",
        "        'save_train_images':'drive/My Drive/GAN_seg/ADDN-master/vm/train',\n",
        "        'train_image_name':'/new_img_trn.npy',\n",
        "        'train_mask_name':'/new_msk_trn.npy',\n",
        "        'val_image_name':\"\",\n",
        "        'val_mask_name':'',\n",
        "        'test_image_name':'/img_tst.npy',\n",
        "        \"weights_path_with_name\":'drive/My Drive/GAN_seg/ADDN-master/vm/checkpoints/pack.hd5',\n",
        "        'savepath':'drive/My Drive/GAN_seg/ADDN-master/vm/predict', \n",
        "        'input_shape': (512, 512, 1),\n",
        "        'output_shape': (512, 512, 1),\n",
        "        'batch_size': 1,\n",
        "        'epochs': 5,\n",
        "        'sample_interval': 200,\n",
        "        'df':64,\n",
        "        'patch':128,\n",
        "        'generator_factor':48\n",
        "        }\n",
        "\n",
        "model=ADDN('trail',data)\n",
        "model.compile()\n",
        "gen,dis,acc= model.train(sample=True)\n",
        "model.test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_46 (InputLayer)           (None, 512, 512, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_47 (InputLayer)           (None, 512, 512, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_370 (Concatenate)   (None, 512, 512, 2)  0           input_46[0][0]                   \n",
            "                                                                 input_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_415 (Conv2D)             (None, 256, 256, 64) 2112        concatenate_370[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, 256, 256, 64) 0           conv2d_415[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_416 (Conv2D)             (None, 128, 128, 128 131200      leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, 128, 128, 128 0           conv2d_416[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_379 (BatchN (None, 128, 128, 128 512         leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_417 (Conv2D)             (None, 128, 128, 256 524544      batch_normalization_379[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, 128, 128, 256 0           conv2d_417[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_380 (BatchN (None, 128, 128, 256 1024        leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_418 (Conv2D)             (None, 128, 128, 1)  4097        batch_normalization_380[0][0]    \n",
            "==================================================================================================\n",
            "Total params: 663,489\n",
            "Trainable params: 662,721\n",
            "Non-trainable params: 768\n",
            "__________________________________________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_48 (InputLayer)           (None, 512, 512, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_419 (Conv2D)             (None, 512, 512, 48) 480         input_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_370 (Dropout)           (None, 512, 512, 48) 0           conv2d_419[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_381 (BatchN (None, 512, 512, 48) 192         dropout_370[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, 512, 512, 48) 0           batch_normalization_381[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_420 (Conv2D)             (None, 512, 512, 12) 5196        activation_361[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_371 (Dropout)           (None, 512, 512, 12) 0           conv2d_420[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_371 (Concatenate)   (None, 512, 512, 60) 0           dropout_370[0][0]                \n",
            "                                                                 dropout_371[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_382 (BatchN (None, 512, 512, 60) 240         concatenate_371[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, 512, 512, 60) 0           batch_normalization_382[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_421 (Conv2D)             (None, 512, 512, 12) 6492        activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_372 (Dropout)           (None, 512, 512, 12) 0           conv2d_421[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_372 (Concatenate)   (None, 512, 512, 72) 0           concatenate_371[0][0]            \n",
            "                                                                 dropout_372[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_383 (BatchN (None, 512, 512, 72) 288         concatenate_372[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, 512, 512, 72) 0           batch_normalization_383[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_422 (Conv2D)             (None, 512, 512, 12) 7788        activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_373 (Dropout)           (None, 512, 512, 12) 0           conv2d_422[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_373 (Concatenate)   (None, 512, 512, 84) 0           concatenate_372[0][0]            \n",
            "                                                                 dropout_373[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_384 (BatchN (None, 512, 512, 84) 336         concatenate_373[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, 512, 512, 84) 0           batch_normalization_384[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_423 (Conv2D)             (None, 512, 512, 12) 9084        activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_374 (Dropout)           (None, 512, 512, 12) 0           conv2d_423[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_374 (Concatenate)   (None, 512, 512, 96) 0           dropout_370[0][0]                \n",
            "                                                                 dropout_371[0][0]                \n",
            "                                                                 dropout_372[0][0]                \n",
            "                                                                 dropout_373[0][0]                \n",
            "                                                                 dropout_374[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_385 (BatchN (None, 512, 512, 96) 384         concatenate_374[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, 512, 512, 96) 0           batch_normalization_385[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_424 (Conv2D)             (None, 512, 512, 96) 83040       activation_365[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_375 (Dropout)           (None, 512, 512, 96) 0           conv2d_424[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling2D) (None, 256, 256, 96) 0           dropout_375[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_386 (BatchN (None, 256, 256, 96) 384         max_pooling2d_37[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, 256, 256, 96) 0           batch_normalization_386[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_425 (Conv2D)             (None, 256, 256, 12) 10380       activation_366[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_376 (Dropout)           (None, 256, 256, 12) 0           conv2d_425[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_375 (Concatenate)   (None, 256, 256, 108 0           max_pooling2d_37[0][0]           \n",
            "                                                                 dropout_376[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_387 (BatchN (None, 256, 256, 108 432         concatenate_375[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 256, 256, 108 0           batch_normalization_387[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_426 (Conv2D)             (None, 256, 256, 12) 11676       activation_367[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_377 (Dropout)           (None, 256, 256, 12) 0           conv2d_426[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_376 (Concatenate)   (None, 256, 256, 120 0           concatenate_375[0][0]            \n",
            "                                                                 dropout_377[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_388 (BatchN (None, 256, 256, 120 480         concatenate_376[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 256, 256, 120 0           batch_normalization_388[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_427 (Conv2D)             (None, 256, 256, 12) 12972       activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_378 (Dropout)           (None, 256, 256, 12) 0           conv2d_427[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_377 (Concatenate)   (None, 256, 256, 132 0           concatenate_376[0][0]            \n",
            "                                                                 dropout_378[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_389 (BatchN (None, 256, 256, 132 528         concatenate_377[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 256, 256, 132 0           batch_normalization_389[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_428 (Conv2D)             (None, 256, 256, 12) 14268       activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_379 (Dropout)           (None, 256, 256, 12) 0           conv2d_428[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_378 (Concatenate)   (None, 256, 256, 144 0           max_pooling2d_37[0][0]           \n",
            "                                                                 dropout_376[0][0]                \n",
            "                                                                 dropout_377[0][0]                \n",
            "                                                                 dropout_378[0][0]                \n",
            "                                                                 dropout_379[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_390 (BatchN (None, 256, 256, 144 576         concatenate_378[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 256, 256, 144 0           batch_normalization_390[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_429 (Conv2D)             (None, 256, 256, 144 186768      activation_370[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_380 (Dropout)           (None, 256, 256, 144 0           conv2d_429[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling2D) (None, 128, 128, 144 0           dropout_380[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_391 (BatchN (None, 128, 128, 144 576         max_pooling2d_38[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 128, 128, 144 0           batch_normalization_391[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_430 (Conv2D)             (None, 128, 128, 12) 15564       activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_381 (Dropout)           (None, 128, 128, 12) 0           conv2d_430[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_379 (Concatenate)   (None, 128, 128, 156 0           max_pooling2d_38[0][0]           \n",
            "                                                                 dropout_381[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_392 (BatchN (None, 128, 128, 156 624         concatenate_379[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 128, 128, 156 0           batch_normalization_392[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_431 (Conv2D)             (None, 128, 128, 12) 16860       activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_382 (Dropout)           (None, 128, 128, 12) 0           conv2d_431[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_380 (Concatenate)   (None, 128, 128, 168 0           concatenate_379[0][0]            \n",
            "                                                                 dropout_382[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_393 (BatchN (None, 128, 128, 168 672         concatenate_380[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 128, 128, 168 0           batch_normalization_393[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_432 (Conv2D)             (None, 128, 128, 12) 18156       activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_383 (Dropout)           (None, 128, 128, 12) 0           conv2d_432[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_381 (Concatenate)   (None, 128, 128, 180 0           concatenate_380[0][0]            \n",
            "                                                                 dropout_383[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_394 (BatchN (None, 128, 128, 180 720         concatenate_381[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 128, 128, 180 0           batch_normalization_394[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_433 (Conv2D)             (None, 128, 128, 12) 19452       activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_384 (Dropout)           (None, 128, 128, 12) 0           conv2d_433[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_382 (Concatenate)   (None, 128, 128, 192 0           max_pooling2d_38[0][0]           \n",
            "                                                                 dropout_381[0][0]                \n",
            "                                                                 dropout_382[0][0]                \n",
            "                                                                 dropout_383[0][0]                \n",
            "                                                                 dropout_384[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_395 (BatchN (None, 128, 128, 192 768         concatenate_382[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 128, 128, 192 0           batch_normalization_395[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_434 (Conv2D)             (None, 128, 128, 192 331968      activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_385 (Dropout)           (None, 128, 128, 192 0           conv2d_434[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling2D) (None, 64, 64, 192)  0           dropout_385[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_396 (BatchN (None, 64, 64, 192)  768         max_pooling2d_39[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 64, 64, 192)  0           batch_normalization_396[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_435 (Conv2D)             (None, 64, 64, 12)   20748       activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_386 (Dropout)           (None, 64, 64, 12)   0           conv2d_435[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_383 (Concatenate)   (None, 64, 64, 204)  0           max_pooling2d_39[0][0]           \n",
            "                                                                 dropout_386[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_397 (BatchN (None, 64, 64, 204)  816         concatenate_383[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, 64, 64, 204)  0           batch_normalization_397[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_436 (Conv2D)             (None, 64, 64, 12)   22044       activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_387 (Dropout)           (None, 64, 64, 12)   0           conv2d_436[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_384 (Concatenate)   (None, 64, 64, 216)  0           concatenate_383[0][0]            \n",
            "                                                                 dropout_387[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_398 (BatchN (None, 64, 64, 216)  864         concatenate_384[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, 64, 64, 216)  0           batch_normalization_398[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_437 (Conv2D)             (None, 64, 64, 12)   23340       activation_378[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_388 (Dropout)           (None, 64, 64, 12)   0           conv2d_437[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_385 (Concatenate)   (None, 64, 64, 228)  0           concatenate_384[0][0]            \n",
            "                                                                 dropout_388[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_399 (BatchN (None, 64, 64, 228)  912         concatenate_385[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, 64, 64, 228)  0           batch_normalization_399[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_438 (Conv2D)             (None, 64, 64, 12)   24636       activation_379[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_389 (Dropout)           (None, 64, 64, 12)   0           conv2d_438[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_386 (Concatenate)   (None, 64, 64, 240)  0           max_pooling2d_39[0][0]           \n",
            "                                                                 dropout_386[0][0]                \n",
            "                                                                 dropout_387[0][0]                \n",
            "                                                                 dropout_388[0][0]                \n",
            "                                                                 dropout_389[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_400 (BatchN (None, 64, 64, 240)  960         concatenate_386[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, 64, 64, 240)  0           batch_normalization_400[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_439 (Conv2D)             (None, 64, 64, 240)  518640      activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_390 (Dropout)           (None, 64, 64, 240)  0           conv2d_439[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling2D) (None, 32, 32, 240)  0           dropout_390[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_401 (BatchN (None, 32, 32, 240)  960         max_pooling2d_40[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 32, 32, 240)  0           batch_normalization_401[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_440 (Conv2D)             (None, 32, 32, 12)   25932       activation_381[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_391 (Dropout)           (None, 32, 32, 12)   0           conv2d_440[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_387 (Concatenate)   (None, 32, 32, 252)  0           max_pooling2d_40[0][0]           \n",
            "                                                                 dropout_391[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_402 (BatchN (None, 32, 32, 252)  1008        concatenate_387[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 32, 32, 252)  0           batch_normalization_402[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_441 (Conv2D)             (None, 32, 32, 12)   27228       activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_392 (Dropout)           (None, 32, 32, 12)   0           conv2d_441[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_388 (Concatenate)   (None, 32, 32, 264)  0           concatenate_387[0][0]            \n",
            "                                                                 dropout_392[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_403 (BatchN (None, 32, 32, 264)  1056        concatenate_388[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 32, 32, 264)  0           batch_normalization_403[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_442 (Conv2D)             (None, 32, 32, 12)   28524       activation_383[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_393 (Dropout)           (None, 32, 32, 12)   0           conv2d_442[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_389 (Concatenate)   (None, 32, 32, 276)  0           concatenate_388[0][0]            \n",
            "                                                                 dropout_393[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_404 (BatchN (None, 32, 32, 276)  1104        concatenate_389[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 32, 32, 276)  0           batch_normalization_404[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_443 (Conv2D)             (None, 32, 32, 12)   29820       activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_394 (Dropout)           (None, 32, 32, 12)   0           conv2d_443[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_390 (Concatenate)   (None, 32, 32, 288)  0           max_pooling2d_40[0][0]           \n",
            "                                                                 dropout_391[0][0]                \n",
            "                                                                 dropout_392[0][0]                \n",
            "                                                                 dropout_393[0][0]                \n",
            "                                                                 dropout_394[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_37 (Conv2DTran (None, 64, 64, 48)   55344       concatenate_390[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_391 (Concatenate)   (None, 64, 64, 288)  0           conv2d_transpose_37[0][0]        \n",
            "                                                                 concatenate_386[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_405 (BatchN (None, 64, 64, 288)  1152        concatenate_391[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 64, 64, 288)  0           batch_normalization_405[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_444 (Conv2D)             (None, 64, 64, 12)   31116       activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_395 (Dropout)           (None, 64, 64, 12)   0           conv2d_444[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_392 (Concatenate)   (None, 64, 64, 300)  0           concatenate_391[0][0]            \n",
            "                                                                 dropout_395[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_406 (BatchN (None, 64, 64, 300)  1200        concatenate_392[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 64, 64, 300)  0           batch_normalization_406[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_445 (Conv2D)             (None, 64, 64, 12)   32412       activation_386[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_396 (Dropout)           (None, 64, 64, 12)   0           conv2d_445[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_393 (Concatenate)   (None, 64, 64, 312)  0           concatenate_392[0][0]            \n",
            "                                                                 dropout_396[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_407 (BatchN (None, 64, 64, 312)  1248        concatenate_393[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 64, 64, 312)  0           batch_normalization_407[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_446 (Conv2D)             (None, 64, 64, 12)   33708       activation_387[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_397 (Dropout)           (None, 64, 64, 12)   0           conv2d_446[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_394 (Concatenate)   (None, 64, 64, 324)  0           concatenate_393[0][0]            \n",
            "                                                                 dropout_397[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_408 (BatchN (None, 64, 64, 324)  1296        concatenate_394[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 64, 64, 324)  0           batch_normalization_408[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_447 (Conv2D)             (None, 64, 64, 12)   35004       activation_388[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_398 (Dropout)           (None, 64, 64, 12)   0           conv2d_447[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_395 (Concatenate)   (None, 64, 64, 336)  0           concatenate_391[0][0]            \n",
            "                                                                 dropout_395[0][0]                \n",
            "                                                                 dropout_396[0][0]                \n",
            "                                                                 dropout_397[0][0]                \n",
            "                                                                 dropout_398[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_38 (Conv2DTran (None, 128, 128, 48) 64560       concatenate_395[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_396 (Concatenate)   (None, 128, 128, 240 0           conv2d_transpose_38[0][0]        \n",
            "                                                                 concatenate_382[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_409 (BatchN (None, 128, 128, 240 960         concatenate_396[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 128, 128, 240 0           batch_normalization_409[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_448 (Conv2D)             (None, 128, 128, 12) 25932       activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_399 (Dropout)           (None, 128, 128, 12) 0           conv2d_448[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_397 (Concatenate)   (None, 128, 128, 252 0           concatenate_396[0][0]            \n",
            "                                                                 dropout_399[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_410 (BatchN (None, 128, 128, 252 1008        concatenate_397[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 128, 128, 252 0           batch_normalization_410[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_449 (Conv2D)             (None, 128, 128, 12) 27228       activation_390[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_400 (Dropout)           (None, 128, 128, 12) 0           conv2d_449[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_398 (Concatenate)   (None, 128, 128, 264 0           concatenate_397[0][0]            \n",
            "                                                                 dropout_400[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_411 (BatchN (None, 128, 128, 264 1056        concatenate_398[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 128, 128, 264 0           batch_normalization_411[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_450 (Conv2D)             (None, 128, 128, 12) 28524       activation_391[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_401 (Dropout)           (None, 128, 128, 12) 0           conv2d_450[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_399 (Concatenate)   (None, 128, 128, 276 0           concatenate_398[0][0]            \n",
            "                                                                 dropout_401[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_412 (BatchN (None, 128, 128, 276 1104        concatenate_399[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 128, 128, 276 0           batch_normalization_412[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_451 (Conv2D)             (None, 128, 128, 12) 29820       activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_402 (Dropout)           (None, 128, 128, 12) 0           conv2d_451[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_400 (Concatenate)   (None, 128, 128, 288 0           concatenate_396[0][0]            \n",
            "                                                                 dropout_399[0][0]                \n",
            "                                                                 dropout_400[0][0]                \n",
            "                                                                 dropout_401[0][0]                \n",
            "                                                                 dropout_402[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_39 (Conv2DTran (None, 256, 256, 48) 55344       concatenate_400[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_401 (Concatenate)   (None, 256, 256, 192 0           conv2d_transpose_39[0][0]        \n",
            "                                                                 concatenate_378[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_413 (BatchN (None, 256, 256, 192 768         concatenate_401[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 256, 256, 192 0           batch_normalization_413[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_452 (Conv2D)             (None, 256, 256, 12) 20748       activation_393[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_403 (Dropout)           (None, 256, 256, 12) 0           conv2d_452[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_402 (Concatenate)   (None, 256, 256, 204 0           concatenate_401[0][0]            \n",
            "                                                                 dropout_403[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_414 (BatchN (None, 256, 256, 204 816         concatenate_402[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 256, 256, 204 0           batch_normalization_414[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_453 (Conv2D)             (None, 256, 256, 12) 22044       activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_404 (Dropout)           (None, 256, 256, 12) 0           conv2d_453[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_403 (Concatenate)   (None, 256, 256, 216 0           concatenate_402[0][0]            \n",
            "                                                                 dropout_404[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_415 (BatchN (None, 256, 256, 216 864         concatenate_403[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 256, 256, 216 0           batch_normalization_415[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_454 (Conv2D)             (None, 256, 256, 12) 23340       activation_395[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_405 (Dropout)           (None, 256, 256, 12) 0           conv2d_454[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_404 (Concatenate)   (None, 256, 256, 228 0           concatenate_403[0][0]            \n",
            "                                                                 dropout_405[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_416 (BatchN (None, 256, 256, 228 912         concatenate_404[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 256, 256, 228 0           batch_normalization_416[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_455 (Conv2D)             (None, 256, 256, 12) 24636       activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_406 (Dropout)           (None, 256, 256, 12) 0           conv2d_455[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_405 (Concatenate)   (None, 256, 256, 240 0           concatenate_401[0][0]            \n",
            "                                                                 dropout_403[0][0]                \n",
            "                                                                 dropout_404[0][0]                \n",
            "                                                                 dropout_405[0][0]                \n",
            "                                                                 dropout_406[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_40 (Conv2DTran (None, 512, 512, 48) 46128       concatenate_405[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_406 (Concatenate)   (None, 512, 512, 144 0           conv2d_transpose_40[0][0]        \n",
            "                                                                 concatenate_374[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_417 (BatchN (None, 512, 512, 144 576         concatenate_406[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, 512, 512, 144 0           batch_normalization_417[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_456 (Conv2D)             (None, 512, 512, 12) 15564       activation_397[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_407 (Dropout)           (None, 512, 512, 12) 0           conv2d_456[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_407 (Concatenate)   (None, 512, 512, 156 0           concatenate_406[0][0]            \n",
            "                                                                 dropout_407[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_418 (BatchN (None, 512, 512, 156 624         concatenate_407[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, 512, 512, 156 0           batch_normalization_418[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_457 (Conv2D)             (None, 512, 512, 12) 16860       activation_398[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_408 (Dropout)           (None, 512, 512, 12) 0           conv2d_457[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_408 (Concatenate)   (None, 512, 512, 168 0           concatenate_407[0][0]            \n",
            "                                                                 dropout_408[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_419 (BatchN (None, 512, 512, 168 672         concatenate_408[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, 512, 512, 168 0           batch_normalization_419[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_458 (Conv2D)             (None, 512, 512, 12) 18156       activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_409 (Dropout)           (None, 512, 512, 12) 0           conv2d_458[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_409 (Concatenate)   (None, 512, 512, 180 0           concatenate_408[0][0]            \n",
            "                                                                 dropout_409[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_420 (BatchN (None, 512, 512, 180 720         concatenate_409[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, 512, 512, 180 0           batch_normalization_420[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_459 (Conv2D)             (None, 512, 512, 12) 19452       activation_400[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_410 (Dropout)           (None, 512, 512, 12) 0           conv2d_459[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_410 (Concatenate)   (None, 512, 512, 192 0           concatenate_406[0][0]            \n",
            "                                                                 dropout_407[0][0]                \n",
            "                                                                 dropout_408[0][0]                \n",
            "                                                                 dropout_409[0][0]                \n",
            "                                                                 dropout_410[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_460 (Conv2D)             (None, 512, 512, 1)  193         concatenate_410[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,127,793\n",
            "Trainable params: 2,112,481\n",
            "Non-trainable params: 15,312\n",
            "__________________________________________________________________________________________________\n",
            "[Epoch 0/5] [Batch 0/2400] [D loss: 2.430992, acc:  25%] [G loss: 58.476719] time: 0:02:06.110007\n",
            "(1, 512, 512, 1)\n",
            "[Epoch 0/5] [Batch 1/2400] [D loss: 3.807045, acc:  17%] [G loss: 42.167511] time: 0:07:49.724763\n",
            "[Epoch 0/5] [Batch 2/2400] [D loss: 2.790721, acc:  24%] [G loss: 32.299488] time: 0:07:52.320801\n",
            "[Epoch 0/5] [Batch 3/2400] [D loss: 1.658527, acc:  29%] [G loss: 25.916874] time: 0:07:54.940170\n",
            "[Epoch 0/5] [Batch 4/2400] [D loss: 1.610453, acc:  34%] [G loss: 16.977539] time: 0:07:57.557661\n",
            "[Epoch 0/5] [Batch 5/2400] [D loss: 1.537305, acc:  41%] [G loss: 15.797691] time: 0:08:00.180018\n",
            "[Epoch 0/5] [Batch 6/2400] [D loss: 1.553963, acc:  29%] [G loss: 20.832899] time: 0:08:02.800558\n",
            "[Epoch 0/5] [Batch 7/2400] [D loss: 1.634534, acc:  40%] [G loss: 20.104879] time: 0:08:05.425217\n",
            "[Epoch 0/5] [Batch 8/2400] [D loss: 1.529284, acc:  30%] [G loss: 14.633560] time: 0:08:08.034975\n",
            "[Epoch 0/5] [Batch 9/2400] [D loss: 1.083168, acc:  50%] [G loss: 20.086012] time: 0:08:10.666685\n",
            "[Epoch 0/5] [Batch 10/2400] [D loss: 0.922683, acc:  42%] [G loss: 14.335693] time: 0:08:13.286448\n",
            "[Epoch 0/5] [Batch 11/2400] [D loss: 0.759429, acc:  46%] [G loss: 14.285995] time: 0:08:15.911224\n",
            "[Epoch 0/5] [Batch 12/2400] [D loss: 0.709638, acc:  44%] [G loss: 14.208810] time: 0:08:18.538452\n",
            "[Epoch 0/5] [Batch 13/2400] [D loss: 0.671994, acc:  44%] [G loss: 14.133440] time: 0:08:21.192552\n",
            "[Epoch 0/5] [Batch 14/2400] [D loss: 0.655203, acc:  45%] [G loss: 14.097335] time: 0:08:23.814258\n",
            "[Epoch 0/5] [Batch 15/2400] [D loss: 0.636940, acc:  45%] [G loss: 14.040463] time: 0:08:26.438630\n",
            "[Epoch 0/5] [Batch 16/2400] [D loss: 0.623188, acc:  45%] [G loss: 14.011144] time: 0:08:29.069700\n",
            "[Epoch 0/5] [Batch 17/2400] [D loss: 0.605740, acc:  45%] [G loss: 13.956267] time: 0:08:31.692032\n",
            "[Epoch 0/5] [Batch 18/2400] [D loss: 0.593955, acc:  47%] [G loss: 19.082155] time: 0:08:34.317412\n",
            "[Epoch 0/5] [Batch 19/2400] [D loss: 0.591161, acc:  46%] [G loss: 13.896552] time: 0:08:36.946398\n",
            "[Epoch 0/5] [Batch 20/2400] [D loss: 0.587169, acc:  46%] [G loss: 13.894651] time: 0:08:39.573653\n",
            "[Epoch 0/5] [Batch 21/2400] [D loss: 0.589119, acc:  45%] [G loss: 13.858896] time: 0:08:42.191571\n",
            "[Epoch 0/5] [Batch 22/2400] [D loss: 0.603155, acc:  43%] [G loss: 13.844795] time: 0:08:44.804606\n",
            "[Epoch 0/5] [Batch 23/2400] [D loss: 0.606093, acc:  41%] [G loss: 13.869284] time: 0:08:47.443438\n",
            "[Epoch 0/5] [Batch 24/2400] [D loss: 0.610923, acc:  42%] [G loss: 13.829143] time: 0:08:50.066252\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}